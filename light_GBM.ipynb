{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalization(x):\n",
    "    max_val = max(x)\n",
    "    min_val = min(x)\n",
    "    return [(i-min_val)/(max_val-min_val) for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_lost_cal(real, pre):\n",
    "    \n",
    "    test_auc = metrics.roc_auc_score(real, pre)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(real, pre, pos_label=1) \n",
    "    score=0.4*tpr[np.where(fpr>=0.001)[0][0]]+0.3*tpr[np.where(fpr>=0.005)[0][0]]+0.3*tpr[np.where(fpr>=0.01)[0][0]] \n",
    "    \n",
    "    print(\"AUC value = \" + str(test_auc))\n",
    "    print(\"Score = \" + str(score))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "root = \"./data/\"\n",
    "data_train = pd.read_csv(root + \"atec_anti_fraud_train.csv\")\n",
    "# data_train_add = pd.read_csv(root + \"predicted_positive_sample_test_add.csv\")\n",
    "data_test = pd.read_csv(root + \"atec_anti_fraud_test_a.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "# 是否要采样\n",
    "# data_train = data_train.sample(100000)\n",
    "# data_train = data_train[data_train['label'] != -1]\n",
    "\n",
    "data_test = data_test.drop(['id'], 1)\n",
    "data_test = data_test.drop(['date'], 1)\n",
    "\n",
    "data_train = data_train.drop(['id'], 1)\n",
    "data_train = data_train.drop(['date'], 1)\n",
    "# data_train_add = data_train_add.drop(['id'], 1)\n",
    "# data_train_add = data_train_add.drop(['date'], 1)\n",
    "# data_train = pd.concat([data_train,data_train_add], sort=True)\n",
    "\n",
    "data_train['label'] = np.abs(data_train['label'])\n",
    "train_y = data_train['label']\n",
    "data_train = data_train.drop(['label'], 1)\n",
    "\n",
    "# 删除特征\n",
    "b = ['20','22','24','26','28','30','32','34','46','47','48','50','52','53','100','13','49','109','107','104','102','161','201']        \n",
    "c = [str(i) for i in range(64,72)]\n",
    "d = [str(i) for i in range(111,155)]\n",
    "\n",
    "drop_col = ['f'+i for i in (b+c+d)]\n",
    "\n",
    "data_test = data_test.drop(drop_col,1)\n",
    "data_train = data_train.drop(drop_col,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = data_train\n",
    "test_x = data_test\n",
    "# train_y = np.array(train_y).reshape(-1, 1)\n",
    "\n",
    "# train_x = np.array(train_x)\n",
    "# train_y = np.array(train_y).reshape(-1, 1)\n",
    "# test_x = np.array(test_x)\n",
    "\n",
    "X = np.array(train_x)\n",
    "Y = np.array(train_y)\n",
    "X_test = test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST：\n",
      "AUC value = 0.9785241738828017\n",
      "Score = 0.4296285463585844\n",
      "done...\n",
      "TEST：\n",
      "AUC value = 0.9789045797174243\n",
      "Score = 0.4292682926829269\n",
      "done...\n",
      "TEST：\n",
      "AUC value = 0.9772136344246202\n",
      "Score = 0.4162308385933273\n",
      "done...\n",
      "TEST：\n",
      "AUC value = 0.9785130922089871\n",
      "Score = 0.41795104261106075\n",
      "done...\n",
      "TEST：\n",
      "AUC value = 0.977036056551142\n",
      "Score = 0.41778425655976675\n",
      "done...\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "# 交叉验证取平均\n",
    "k = 5\n",
    "kf = KFold(n_splits = k, shuffle=True, random_state=2)\n",
    "# kf = KFold(n_splits=k)\n",
    "\n",
    "eta = 0.05\n",
    "result = 0\n",
    "xgb_result = 0\n",
    "importances = 0\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X1_train, X1_test = X[train_index], X[test_index]\n",
    "    Y1_train, Y1_test = Y[train_index], Y[test_index]\n",
    "\n",
    "    data_train = lgb.Dataset(X1_train, Y1_train)\n",
    "    data_vtest = lgb.Dataset(X1_test, Y1_test)\n",
    "#     data_rtest = lgb.Dataset(X_test)\n",
    "    param = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',  # 二分类问题\n",
    "        # max_depth, gamma, subsample+colsample_bytree, \n",
    "        'max_depth': 5,  # 构建树的深度，越大越容易过拟合\n",
    "        'lambda_l2': 1,\n",
    "#         'num_leaves': 63,\n",
    "#         'lambda':1,  # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。\n",
    "        'gamma':0.1,\n",
    "        'subsample':0.8,\n",
    "        'colsample_bytree':0.8,\n",
    "        'seed' : 1,\n",
    "        'scale_pos_weight':1,\n",
    "        # 'min_child_weight':4,\n",
    "        # 这个参数默认是 1，是每个叶子里面 h 的和至少是多少，对正负样本不均衡时的 0-1 分类而言\n",
    "        # ，假设 h 在 0.01 附近，min_child_weight 为 1 意味着叶子节点中最少需要包含 100 个样本。\n",
    "        # 这个参数非常影响结果，控制叶子节点中二阶导的和的最小值，该参数值越小，越容易 overfitting。\n",
    "         'verbosity': 0,  # 设置成1则没有运行信息输出，最好是设置为0.\n",
    "        'eta': eta,  # 如同学习率\n",
    "        'metric': 'auc'\n",
    "    }\n",
    "    bst = lgb.train(param, data_train, num_boost_round=100)\n",
    "    \n",
    "#     print(\"TRAIN\")\n",
    "#     xgb_tra = bst.predict(data_train)  # 训练集\n",
    "#     weight_lost_cal(Y1_train.reshape(-1, 1), xgb_tra.reshape(-1, 1))\n",
    "    \n",
    "    print(\"TEST：\")\n",
    "    xgb_val = bst.predict(X1_test)  # 交叉验证集\n",
    "    \n",
    "    xgb_result += bst.predict(X_test)  # 测试集\n",
    "#     xgb_result += 1-cur_result  # 测试集\n",
    "\n",
    "    result += weight_lost_cal(Y1_test.reshape(-1, 1), xgb_val.reshape(-1, 1))\n",
    "\n",
    "    print(\"done...\")\n",
    "    \n",
    "# 计算结果\n",
    "result /= k\n",
    "xgb_result /= k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4221725953611332\n",
      "0.8617259595966573\n",
      "0.00021068815700912442\n"
     ]
    }
   ],
   "source": [
    "print(result)\n",
    "print(max(xgb_result))\n",
    "print(min(xgb_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出\n",
    "data_test = pd.read_csv(root + \"atec_anti_fraud_test_a.csv\")\n",
    "data_test['score'] = xgb_result\n",
    "data_test['score'].round(decimals=5)\n",
    "data = data_test[['id', 'score']]  #选择表格中的两列\n",
    "data.to_csv(root + \"result_717_1500_V2.csv\", index=None, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
